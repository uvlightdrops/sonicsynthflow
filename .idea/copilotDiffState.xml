<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/test_aubio_max.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/test_aubio_max.py" />
              <option name="originalContent" value="import pyaudio&#10;import aubio&#10;import numpy as np&#10;from time import sleep&#10;import collections&#10;from rich.console import Console&#10;from rich.table import Table&#10;from rich.live import Live&#10;from rich.panel import Panel&#10;from rich.layout import Layout&#10;import time&#10;&#10; &#10;seconds = 20 # how long this script should run&#10; &#10;bufferSize = 512&#10;windowSizeMultiple = 4 # or 4 for higher accuracy, but more computational cost&#10; &#10;audioInputDeviceIndex = 4&#10;audioInputChannels = 1&#10;&#10;window_size = 5  # Anzahl der Werte für den Moving Average&#10;bpm_values = collections.deque(maxlen=window_size)&#10;console = Console()&#10;&#10;# create the aubio tempo detection:&#10;hopSize = bufferSize&#10;winSize = hopSize * windowSizeMultiple&#10;### byflo&#10;pa = pyaudio.PyAudio()&#10;&#10;def check_devices():&#10;    print(&quot;Available audio input devices:&quot;)&#10;    # use 'arecord -l' to check available audio devices&#10;    for i in range(pa.get_device_count()):&#10;        info = pa.get_device_info_by_index(i)&#10;        print(f&quot;Index: {i}, Name: {info['name']}, Max Input Channels: {info['maxInputChannels']}&quot;)&#10;    print()&#10;check_devices()&#10;&#10;audioInputDevice = pa.get_device_info_by_index(audioInputDeviceIndex)&#10;print(&quot;Using audio input device:&quot;, audioInputDevice['name'])&#10;&#10;audioInputSampleRate = int(audioInputDevice['defaultSampleRate'])&#10;print(&quot;Audio input sample rate:&quot;, audioInputSampleRate)&#10;&#10;tempoDetection = aubio.tempo(method='default', buf_size=winSize, hop_size=hopSize, samplerate=audioInputSampleRate)&#10;&#10;def is_outlier(value, values, threshold=2.5):&#10;    if len(values) &lt; 2:&#10;        return False&#10;    mean = np.mean(values)&#10;    std = np.std(values)&#10;    print(f&quot;Mean: {mean}, Std: {std}, Value: {value}&quot;)&#10;    if std == 0:&#10;        return False&#10;    z_score = abs((value - mean) / std)&#10;    return z_score &gt; threshold&#10;&#10;# this function gets called by the input stream, as soon as enough samples are collected from the audio input:&#10;def readAudioFrames(in_data, frame_count, time_info, status):&#10;    global last_bpm&#10;&#10;    signal = np.frombuffer(in_data, dtype=np.float32)&#10;    beat = tempoDetection(signal)&#10;    if beat:&#10;        bpm = tempoDetection.get_bpm()&#10;        if not is_outlier(bpm, list(bpm_values)):&#10;            bpm_values.append(bpm)&#10;            avg_bpm = np.mean(bpm_values)&#10;            console.print(f&quot;BPM (Moving Average): {avg_bpm:.2f}   &quot;, end=&quot;\r&quot;, highlight=False)&#10;        else:&#10;            console.log(f&quot;Ausreißer erkannt: {bpm:.2f}&quot;)&#10;    return (in_data, pyaudio.paContinue)&#10; &#10; &#10;# create and start the input stream&#10;inputStream = pa.open(format=pyaudio.paFloat32,&#10;                input=True,&#10;                channels=audioInputChannels,&#10;                input_device_index=audioInputDeviceIndex,&#10;                frames_per_buffer=bufferSize,&#10;                rate=audioInputSampleRate,&#10;                stream_callback=readAudioFrames)&#10; &#10; &#10;# because the input stream runs asynchronously, we just wait for a few seconds here before stopping the script:&#10;sleep(seconds)&#10; &#10;inputStream.stop_stream()&#10;inputStream.close()&#10;pa.terminate()&#10;" />
              <option name="updatedContent" value="import pyaudio&#10;import aubio&#10;import numpy as np&#10;import collections&#10;from rich.console import Console&#10;from rich.table import Table&#10;from rich.live import Live&#10;from rich.panel import Panel&#10;from rich.layout import Layout&#10;import time&#10;&#10;class BPMMonitorApp:&#10;    def __init__(self, device_index=4, channels=1, buffer_size=512, window_mult=4, window_size=5):&#10;        self.device_index = device_index&#10;        self.channels = channels&#10;        self.buffer_size = buffer_size&#10;        self.window_mult = window_mult&#10;        self.window_size = window_size&#10;        self.bpm_values = collections.deque(maxlen=window_size)&#10;        self.outliers = []&#10;        self.single_measurements = []&#10;        self.console = Console()&#10;        self.pa = pyaudio.PyAudio()&#10;        self.audio_device = self.pa.get_device_info_by_index(device_index)&#10;        self.sample_rate = int(self.audio_device['defaultSampleRate'])&#10;        self.tempoDetection = aubio.tempo(method='default', buf_size=buffer_size*window_mult, hop_size=buffer_size, samplerate=self.sample_rate)&#10;        self.start_time = time.time()&#10;        self.status = &quot;Initialisiert&quot;&#10;&#10;    def is_outlier(self, value, values, threshold=2.5):&#10;        if len(values) &lt; 2:&#10;            return False&#10;        mean = np.mean(values)&#10;        std = np.std(values)&#10;        if std == 0:&#10;            return False&#10;        z_score = abs((value - mean) / std)&#10;        return z_score &gt; threshold&#10;&#10;    def readAudioFrames(self, in_data, frame_count, time_info, status):&#10;        signal = np.frombuffer(in_data, dtype=np.float32)&#10;        beat = self.tempoDetection(signal)&#10;        if beat:&#10;            bpm = self.tempoDetection.get_bpm()&#10;            self.single_measurements.append(bpm)&#10;            if not self.is_outlier(bpm, list(self.bpm_values)):&#10;                self.bpm_values.append(bpm)&#10;            else:&#10;                self.outliers.append(bpm)&#10;        return (in_data, pyaudio.paContinue)&#10;&#10;    def make_layout(self):&#10;        layout = Layout()&#10;        layout.split_column(&#10;            Layout(name=&quot;upper&quot;, ratio=3),&#10;            Layout(name=&quot;status&quot;, ratio=1)&#10;        )&#10;        layout[&quot;upper&quot;].split_row(&#10;            Layout(name=&quot;avg_bpm&quot;),&#10;            Layout(name=&quot;single_bpm&quot;),&#10;            Layout(name=&quot;outliers&quot;)&#10;        )&#10;        return layout&#10;&#10;    def render(self):&#10;        layout = self.make_layout()&#10;        # Avg BPM Panel&#10;        avg_bpm = np.mean(self.bpm_values) if self.bpm_values else 0.0&#10;        avg_panel = Panel(f&quot;[bold green]{avg_bpm:.2f}[/]&quot;, title=&quot;Moving Average BPM&quot;, border_style=&quot;green&quot;)&#10;        layout[&quot;avg_bpm&quot;].update(avg_panel)&#10;        # Einzelmessungen Tabelle&#10;        table = Table(title=&quot;Einzelmessungen&quot;, show_header=True, header_style=&quot;bold magenta&quot;)&#10;        table.add_column(&quot;#&quot;, justify=&quot;right&quot;)&#10;        table.add_column(&quot;BPM&quot;, justify=&quot;right&quot;)&#10;        for i, bpm in enumerate(self.single_measurements[-10:], 1):&#10;            table.add_row(str(i), f&quot;{bpm:.2f}&quot;)&#10;        layout[&quot;single_bpm&quot;].update(table)&#10;        # Ausreißer Tabelle&#10;        out_table = Table(title=&quot;Ausreißer&quot;, show_header=True, header_style=&quot;bold red&quot;)&#10;        out_table.add_column(&quot;#&quot;, justify=&quot;right&quot;)&#10;        out_table.add_column(&quot;BPM&quot;, justify=&quot;right&quot;)&#10;        for i, bpm in enumerate(self.outliers[-10:], 1):&#10;            out_table.add_row(str(i), f&quot;{bpm:.2f}&quot;)&#10;        layout[&quot;outliers&quot;].update(out_table)&#10;        # Status Panel&#10;        elapsed = int(time.time() - self.start_time)&#10;        status_text = f&quot;Gerät: {self.audio_device['name']} | SampleRate: {self.sample_rate} | Laufzeit: {elapsed}s | Status: {self.status}&quot;&#10;        layout[&quot;status&quot;].update(Panel(status_text, title=&quot;Status&quot;, border_style=&quot;blue&quot;))&#10;        return layout&#10;&#10;    def run(self):&#10;        inputStream = self.pa.open(format=pyaudio.paFloat32,&#10;                input=True,&#10;                channels=self.channels,&#10;                input_device_index=self.device_index,&#10;                frames_per_buffer=self.buffer_size,&#10;                rate=self.sample_rate,&#10;                stream_callback=self.readAudioFrames)&#10;        self.status = &quot;Läuft&quot;&#10;        with Live(self.render(), refresh_per_second=2, screen=True):&#10;            try:&#10;                while True:&#10;                    time.sleep(0.5)&#10;            except KeyboardInterrupt:&#10;                self.status = &quot;Beendet durch Benutzer&quot;&#10;                inputStream.stop_stream()&#10;                inputStream.close()&#10;                self.pa.terminate()&#10;&#10;if __name__ == &quot;__main__&quot;:&#10;    app = BPMMonitorApp()&#10;    app.run()" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>